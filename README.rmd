# Market Matching and Causal Impact Inference
If you ever spent time in the field of marketing analytics, chances are that you have analyzed the existence of a causal impact from a new TV campaign, a major PR event, or the emergence of a new local competitor using some sort of time series approach. The impact of such events cannot be tracked at the individual customer level and we do not have the luxury of clean test and control groups. Instead we have to analyze the impact from a bird's eye view using time series analysis at the market level (e.g., DMA, state, etc.). Data science may be changing at a fast pace but this is an old school use-case that is still very relevant no matter what industry you're in.

Intervention analyses require more judgement than evaluation of standard, randomized test/control studies. When analyzing interventions through time series analysis we typically go through two steps, each of which can involve multiple decisions:

1. Find matching *control* markets for the *test* market where the event took place using time series matching based on historical data prior to the event (the "pre period").
2. Analyze the causal impact of the event by comparing the observed data for the test and control markets following the event (the "post period"), while factoring in differences between the markets prior to the event.

The purpose of this Vignette is to describe a robust approach to intervention analysis and introduce a small `R` package that implements the workflow. 

## A Traditional Approach
For the first step, the most straightforward approach is to use the Euclidian distance to find matching control markets. However, this approach implicitly over-penalizes instances where the markets are shifted. Although it is preferable for test and control markets to be aligned consistently, occasional historical shifts should not eliminate viable control market candidates.

For the second step, the traditional approach is a "diff in diff" analysis. This is typically a static regression model that evaluates the change in the difference between the test and control markets before and after the event. However, this assumes that observations are i.i.d. and that the differences between the test and control markets, before and after the event, are constant. Both assumptions rarely hold true for time series data.

## A More Flexible and Robust Approach
A better approach is to use *dynamic time warping* for the time series matching step. This technique finds the distance along the *warping curve* – instead of the raw data – where the warping curve represents the best alignment between two time series within some user-defined constraints. Note that the Euclidian distance is a special case of the warped distance.

For the intervention analysis the `CausalImpact` package created by Kay Brodersen at Google provides an approach that is more flexible and robust than the "diff in diff" model  (see [1]). The `CausalImpact` package constructs a synthetic baseline for the post-intervention period based on a Bayesian structural time series model that leverages *multiple* matching control markets as predictors as well as other features of the time series.

We can summarize this workflow as follows:

1. Find the best control markets for each market in the dataset using dynamic time warping. The user can define how many matches should be retained. Note that this step merely creates a list of candidates markets; the final markets used for the post-event inference will be decided in the next step. 

2. Fit a Bayesian structural time series model that utilizes the control markets identified in step 1 as predictors. Based on this model, create a synthetic control series by producing a counterfactual prediction for the post period assuming that the event did not take place. Then calculate the difference between the synthetic control and the test market for the post-intervention period – which is the estimated impact of the event – and compare to the posterior interval to gauge uncertainty. 

### Notes on the Workflow
As stated above, the purpose of the dynamic time warping step is to create a list of viable control market candidates. This is not a strictly necessary step as we can select markets directly while building the time series model during step 2. In fact, the `CausalImpact` package selects the most predictive markets for the structural time series model using spike-and-slab priors which means that we can potentially jump directly to step 2.

However, when dealing with a large set of candidate control markets it often turns out to be prudent to trim the list in advance as opposed to relying solely on the variable selection process. In other words, pre-screening the markets is akin to wearing belt and suspenders; you're much less likely to get an indefensible model. Creating a synthetic control based on markets that have small *distances* to the test market tends to boost the face-validity of the analysis as these control markets will be similar in "size" and hence be recognized as viable controls through visual inspection.  Ultimately, however, this is a matter of preference and the good news is that the `MarketMatching` package allows users to decide how many control markets should pass through step 1.

Last, but not least, one can argue that the initial screening should be correlation-based and that distances are irrelevant – i.e., the "sizes" of the control markets do not matter as long as they are predictive. Again, this is a matter of preference and `MarketMatching` allows the user to control whether the ranking is correlation-based or distance-based.

# About MarketMatching Package

The `MarketMatching` package implements the workflow described above by essentially providing an easy-to-use "wrapper" for the `dtw` and `CausalImpact`. The function `best_matches()` finds the best control markets for each market by looping through all viable candidates in a parallel fashion and then ranking by distance and/or correlation. The resulting output object can then be passed to the `inference()` function which then analyzes the causal impact of an event using the control markets identified by `best_matches()`. 

Hence, the package does *not* provide any core functionality that cannot be found in these packages but it simplifies the workflow of using `dtw` and `CausalImpact` together *and* provides charts and data that are easy to manipulate. R packages are simply a great way of implementing and documenting workflows.

## Summary of features:

* Minimal inputs required. The only strictly necessary inputs are the name of the test market (for inference), the dates of the pre-period and post-period and, of course, the data.
* Provides a data.frame with the best matches for all markets in the input dataset. The number of matches can be defined by the user.
* Outputs all inference results as objects with intuitive names (e.g., "AbsoluteEffect" and "RelativeEffect").
* Checks the quality of the input data and eliminates "bad" markets.
* Calculates MAPE and Durbin-Watson for the pre-period. Shows how these statistics change when you alter the prior standard error of the local level term.
* Plots and outputs the actual data for the markets selected during the initial market matching.
* Plots and outputs actual versus predicted values.
* Plots the final local level term.
* Shows the average estimated coefficients for all the markets used in the linear regression component of the structural time series model.
* Allows the user to choose how many markets are sent to the slab-and-prior model.
* All plots are done in `ggplot2` and can easily be extracted and manipulated.

# How to Install
```{r, eval=FALSE}
library(devtools)
install_github("google/CausalImpact")
install_github("klarsen1/MarketMatching", build_vignettes=TRUE)
```

# Example
The dataset supplied with the package has daily temperature readings for 20 areas (airports) for 2014. The dataset is a stacked time series (panel data) where each row represents a unique combination of date and area. It has three columns: area, date, and the average temperature reading for the day.

This is *not* the most appropriate dataset to demonstrate intervention inference, as humans cannot affect the weather in the short term (long term impact is a different blog post). We'll merely use the data to demonstrate the features.

```{r, echo = TRUE, message=FALSE, eval=FALSE}
##-----------------------------------------------------------------------
## Find the best matches (default is 5) for each airport time series
##-----------------------------------------------------------------------
library(MarketMatching)
data(weather, package="MarketMatching")
mm <- best_matches(data=weather,
                   id_variable="Area",
                   date_variable="Date",
                   matching_variable="Mean_TemperatureF",
                   parallel=TRUE,
                   warping_limit=1, # warping limit=1
                   dtw_emphasis=1, # rely only on dtw for pre-screening
                   matches=5, # request 5 matches
                   start_match_period="2014-01-01",
                   end_match_period="2014-10-01")
##-----------------------------------------------------------------------
## Analyze causal impact of a made-up weather intervention in Copenhagen
## Since this is weather data it is a not a very meaningful example.
## This is merely to demonstrate the function.
##-----------------------------------------------------------------------
library(CausalImpact)
results <- MarketMatching::inference(matched_markets = mm,
                                    test_market = "CPH",
                                    end_post_period = "2015-10-01")
```

A view of the best matches data.frame generated by the best_matches() function:
```{r, echo = TRUE, message=FALSE, eval=FALSE, results='asis'}
knitr::kable(head(mm$BestMatches))
```

Plot actual observations for test market (CPH) versus the expectation. It looks like CPH deviated from its expectation during the winter:
```{r, echo = TRUE, message=FALSE, eval=FALSE, fig.width=7, fig.height=5}
results$PlotActualVersusExpected
```

Plot the cumulative impact. The posterior interval includes zero as expected, which means that the cumulative deviation is likely noise:
```{r, echo = TRUE, message=FALSE, eval=FALSE, fig.width=7, fig.height=5}
results$PlotCumulativeEffect
```

Although it looks like some of the dips in the *point-wise* effects toward the end of the post period seem to be truly negative:
```{r, echo = TRUE, message=FALSE, eval=FALSE, fig.width=7, fig.height=5}
results$PlotPointEffect
```

Store the actual versus predicted values in a data.frame:
```{r, echo = TRUE, message=FALSE, eval=FALSE, results='asis'}
pred <- results$Predictions
knitr::kable(head(pred))
```

Plot the actual data for the test and control markets:
```{r, echo = TRUE, message=FALSE, eval=FALSE, fig.width=7, fig.height=5}
results$PlotActuals
```

Check the Durbin-Watson statistic (DW), MAPE and largest market coefficient for different values of the local level SE. It looks like it will be hard to get a DW statistic close to 2, although our model may benefit from a higher local level standard error than the default of 0.01:
```{r, echo = TRUE, message=FALSE, eval=FALSE, fig.width=7, fig.height=5}
results$PlotPriorLevelSdAnalysis
```

Store the average posterior coefficients in a data.frame. STR (Stuttgart) receives the highest weight when predicting the weather in Copenhagen:
```{r, echo = TRUE, message=FALSE, eval=FALSE, results='asis'}
coeff <- results$Coefficients
knitr::kable(head(coeff))
```

# References
[1] CausalImpact version 1.0.3, Brodersen et al., Annals of Applied Statistics (2015). http://google.github.io/CausalImpact/

[2] Vignette for the `dtw` package: https://cran.r-project.org/web/packages/dtw/vignettes/dtw.pdf.

[3] Predicting the Present with Bayesian Structural Time Series, Steven L. Scott and Hal Varian, http://people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf.